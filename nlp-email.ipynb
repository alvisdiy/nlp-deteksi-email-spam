{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8a8351",
   "metadata": {},
   "source": [
    "## masukan library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b69b6d",
   "metadata": {},
   "source": [
    "## load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indo = pd.read_csv('email_spam_indo.csv')\n",
    "eng = pd.read_csv('spam.csv')\n",
    "\n",
    "indo.columns = [\"label\", \"text\"]\n",
    "eng.columns = [\"label\", \"text\"]\n",
    "\n",
    "data = pd.concat([indo, eng], ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc19d1",
   "metadata": {},
   "source": [
    "## text perporcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc8aa2",
   "metadata": {},
   "source": [
    "#case folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#membuat fungsi u/ case folding\n",
    "def casefolding(text):\n",
    "    text = text.lower()                                  #merubah kalimat menjadi huruf kecil\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+','' , text)   #menghapus url\n",
    "    text = re.sub(r'[-+]?[0-9]+','', text)              #menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)                 #menghapus tanda baca\n",
    "    text = text.strip()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#membandingkan before dan after casefolding\n",
    "raw_sample = data['text'].iloc[696]\n",
    "case_folding = casefolding(raw_sample)\n",
    "\n",
    "print('Before Case Folding : ', raw_sample)\n",
    "print('After Case Folding  : ', case_folding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d192cc",
   "metadata": {},
   "source": [
    "## normalisasi kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_norm = pd.read_csv('key_norm.csv')\n",
    "\n",
    "def text_normalize(text):\n",
    "    text = ' '.join([key_norm[key_norm['singkat'] == word]['hasil'].values[0]\n",
    "    if (key_norm['singkat'] == word).any() \n",
    "    else word for word in text.split()\n",
    "    ])\n",
    "    text = str.lower(text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before and after normalisasi\n",
    "\n",
    "raw_data = data['text'].iloc[696]\n",
    "word_normal = text_normalize(case_folding)\n",
    "\n",
    "print('raw data : ', raw_data)\n",
    "print('after normalisasi : ', word_normal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6a69a",
   "metadata": {},
   "source": [
    "## filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_ind = stopwords.words('indonesian')\n",
    "stopwords_eng = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf292b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stopwords_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stopwords_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melihat daftar topword dari nltk\n",
    "stopwords_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f060664",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#membuat fungsi stopwords removal\n",
    "\n",
    "#menambahkan kata dalam stopwords\n",
    "#more_stopword = ['tsel','gb','rb', 'btw']\n",
    "#stopwords_ind = stopwords\n",
    "all_stopwords = stopwords_ind + stopwords_eng\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    clean_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word not in all_stopwords:\n",
    "            clean_words.append(word)\n",
    "    return ' '.join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample = data['text'].iloc[696]\n",
    "case_folding = casefolding(raw_sample)\n",
    "stopwords_removal = remove_stopwords(case_folding)\n",
    "\n",
    "print('raw data : ', raw_sample)\n",
    "print('case folding : ', case_folding)\n",
    "print('stopwords removal : ', stopwords_removal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5afe0",
   "metadata": {},
   "source": [
    "## stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merubah kata menjadi bentuk dasar\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "#membuat fungsi stemming bahasa indonesia\n",
    "def stemming(text):\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample = data['text'].iloc[696]\n",
    "case_folding = casefolding(raw_sample)\n",
    "stopwords_removal = remove_stopwords(case_folding)\n",
    "text_stemming = stemming(stopwords_removal)\n",
    "\n",
    "print('raw data : ', raw_sample)\n",
    "print('case folding : ', case_folding)\n",
    "print('stopwords removal : ', stopwords_removal)\n",
    "print('text stemming : ', text_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19940cf7",
   "metadata": {},
   "source": [
    "## text preprocessing pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#membuat fungsi u/ menggabungkan semua proses text preprocessing\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    text = casefolding(text)\n",
    "    text = text_normalize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemming(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "\n",
    "data['clean_text'] = data['text'].swifter.apply(text_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df9ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simpan ke file csv\n",
    "data.to_csv('dataset_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8023eb3f",
   "metadata": {},
   "source": [
    "## feature enginering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93846ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pisahkan kolom feature dan target\n",
    "import pandas as pd\n",
    "\n",
    "clean_data = pd.read_csv('dataset_clean.csv')\n",
    "clean_data = clean_data.dropna(subset=['clean_text', 'label'])\n",
    "x = clean_data['clean_text']\n",
    "y = clean_data['label']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d54868",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103dc28",
   "metadata": {},
   "source": [
    "## feature extraction (TF-IDF dan N-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a545976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Unigram\n",
    "vec_TF_IDF = TfidfVectorizer(ngram_range=(1,1))\n",
    "vec_TF_IDF.fit(x)\n",
    "\n",
    "x_tf_idf = vec_TF_IDF.transform(x)\n",
    "\n",
    "pickle.dump(vec_TF_IDF.vocabulary_,open(\"feature_tf-idf.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c032fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#menampilakan vocabulary tf-idf\n",
    "vec_TF_IDF.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melihat jumlah fitur\n",
    "print(len(vec_TF_IDF.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b58a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melihat fitur\n",
    "print(vec_TF_IDF.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = vec_TF_IDF.transform(x).toarray()\n",
    "data_tabular_tf_idf = pd.DataFrame(data=x1, columns=vec_TF_IDF.get_feature_names_out())\n",
    "data_tabular_tf_idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63066f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tabular_tf_idf.iloc[10:20,60:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b6f93",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(data_tabular_tf_idf)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad26056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "chi2_features = SelectKBest(chi2, k=5000)\n",
    "x_kbest_features = chi2_features.fit_transform(x_train, y_train)\n",
    "\n",
    "# reduce fitur\n",
    "print('Original feature number:', x_train.shape[1])\n",
    "print('Reduced feature number:', x_kbest_features.shape[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78431542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gunakan chi2_features.scores_, bukan x_kbest_features.scores_\n",
    "data = pd.DataFrame(chi2_features.scores_, columns=['Nilai'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f90164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan feature beserta nilainya\n",
    "\n",
    "feature = vec_TF_IDF.get_feature_names_out()\n",
    "feature\n",
    "\n",
    "data['Fitur'] = feature\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengurutkan fitur berdasarkan nilai tertinggi\n",
    "data.sort_values(by=['Nilai'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = chi2_features.get_support()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#menampilkan fitur yang terpilih berdasarkan nilai mask / nilai tertinggi yg sudah ditetapkan pada chi square\n",
    "\n",
    "new_features = []\n",
    "for bool, f in zip(mask, feature):\n",
    "    if bool:\n",
    "        new_features.append(f)\n",
    "    selected_features = new_features\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_selected_features = {}\n",
    "\n",
    "for (k,v) in vec_TF_IDF.vocabulary_.items():\n",
    "    if k in selected_features:\n",
    "        new_selected_features[k] =v\n",
    "\n",
    "new_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_selected_features,open(\"new_selected_features_tf-idf.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected_features = pd.DataFrame(x_kbest_features, columns=selected_features)\n",
    "data_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7f799",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9503965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library u/ modeling\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import algorithm naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6508850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_x = data_selected_features  \n",
    "selected_y = y   # target label\n",
    "\n",
    "\n",
    "\n",
    "# Misal dataset sudah ada di variabel x dan y\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    selected_x, selected_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print('banyaknya x_train  :', len(x_train))\n",
    "print('banyaknya x_test   :', len(x_test))\n",
    "print('banyaknya y_train  :', len(y_train))\n",
    "print('banyaknya y_test   :', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa962641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ca0f6",
   "metadata": {},
   "source": [
    "## evaluasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Prediksi dengan data uji \n",
    "y_pred = nb_model.predict(x_test)\n",
    "\n",
    "#Evaluasi\n",
    "print(\"Akurasi :\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nb_model, open(\"model_email.sav\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
